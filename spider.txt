#赶集网的信息爬取
import requests
from bs4 import BeautifulSoup
import csv
 
def getHTMLText(url):
    try:
        r = requests.get(url,timeout=30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except:
        return '产生异常'
 
def get_data(list,html):
    soup = BeautifulSoup(html,'html.parser')
    infos = soup.find('div',{'class':'f-list js-tips-list'}).find_all('div',{'class':'f-list-item ershoufang-list'})
    #infos = soup.find('div',{'class':'f-list js-tips-list'}).find('div',{'class':'f-list-item ershoufang-list'}) 
    with open(r'g:ganji03.csv','a',encoding='utf-8') as f:
        for info in infos:
            name = info.find('dd',{'class':'dd-item title'}).find('a').string
            area =info.find('dd',{'class':'dd-item size'}).find_all('span')[2].string
            price=info.find('dd',{'class':'dd-item info'}).find('div',{'class':'price'}).find_all('span')[0].string
            
            f.write("{},{},{}\n".format(name,area,price))
      
def main():
    start_url = 'http://hz.ganji.com/wblist/ershoufang/pn'
    #start_url = 'https://sh.lianjia.com/ershoufang/pg'
    depth = 30
    info_list =[]
    for i in range(depth):
        url = start_url + str(i)
        html = getHTMLText(url)
        get_data(info_list,html)
main()